---
title: "PrepareCorpusXML"
author: "Olga Alieva"
date: "2022-12-10"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Description 

This file contains code for extracting a corpus of selected Ancient Greek texts from Perseus' Canonical Greek Literature repository <https://github.com/PerseusDL/canonical-greekLit>.

## Load libraries
```{r}
library(XML)
library(dplyr)
library(stringr)
library(ggplot2)
```

# Get Files
```{r}
files = list.files(path = "./xml_corpus", pattern = ".xml")
```

# Get names and authors
```{r warning=FALSE}
## Get names and authors 
data <- c()

for (i in 1:length(files)){
  doc <- xmlTreeParse(paste("./xml_corpus/", files[i], sep = ""), useInternalNodes = T)
  title <- xmlValue(getNodeSet(doc, "/tei:TEI/tei:teiHeader/tei:fileDesc/tei:titleStmt/tei:title", namespaces = c(tei = "http://www.tei-c.org/ns/1.0")))
  author <- xmlValue(getNodeSet(doc, "/tei:TEI/tei:teiHeader/tei:fileDesc/tei:titleStmt/tei:author", namespaces = c(tei = "http://www.tei-c.org/ns/1.0")))
  
  if(is.list(title) != T || is.list(author) != T) {
    data <- rbind(data, c(i, author, title))
    
  } else {
    
    author <- xpathSApply(doc, "//titleStmt/author", xmlValue)
    title <- xpathSApply(doc, "//titleStmt/title", xmlValue)
    data <- rbind(data, c(i, author, title))
  }}

data <- as.data.frame(data)

```

# Add numeric codes
```{r}
# Add numeric codes for authors and works
codes <- gsub("\\.perseus-grc1.xml", "", files)
codes <- gsub("\\.perseus-grc2.xml", "", codes)
data <- cbind(data, codes)
colnames(data) <- c("id", "author", "text", "code")
data$author <- gsub("\\W.+", "", data$author)
```

## Add texts (1)
```{r}
# add texts 1
for (i in 1:length(files)){
  doc <- xmlTreeParse(paste("./xml_corpus/", files[i], sep = ""),
                      useInternalNodes = T)
  node <- getNodeSet(doc, "/tei:TEI//tei:text//tei:body//tei:div//tei:p",
                     namespaces = c(tei = "http://www.tei-c.org/ns/1.0"))
  text <- as.character(xmlValue(node))
  text.clean <- gsub("\n", " ", text)
  text.v <- paste(text.clean, collapse = ' ')
  data[i,5] <- text.v}

idx <- which(data[,5] != "")
data1 <- data[idx, ]
```

## Add texts (2)
```{r}
# add texts 2
files2 <- files[-idx]
data2 <- data[-idx, ]

for (i in 1:length(files2)){
  doc <- xmlTreeParse(paste("./xml_corpus/", files2[i], sep = ""), 
                      useInternalNodes = T)
  node <- getNodeSet(doc, "//text//body//p",
                     namespaces = c(tei =    
                                      "http://www.tei-c.org/ns/1.0"))
  if(length(node) != 0) {
    text <- as.character(xmlValue(node))
    text.clean <- gsub("\n", " ", text)
    text.v <- paste(text.clean, collapse = ' ')
    data2[i,5] <- text.v
  } else {
    node <- getNodeSet(doc, "//tei:text//tei:body//tei:p",
                       namespaces = c(tei = "http://www.tei-c.org/ns/1.0"))
    text <- as.character(xmlValue(node))
    text.clean <- gsub("\n", " ", text)
    text.v <- paste(text.clean, collapse = ' ')
    data2[i,5] <- text.v
  }
}
```

# Bind texts
```{r}
# bind all texts
corpus2 <- as_tibble(rbind(data1, data2)) %>% 
  select(-id, -code) %>% 
  rename(work = text, text = V5)
```

# Tidy up
```{r}
# tidy up
# remove several capital Greek letters in a row 
corpus2$text <- corpus2$text %>% 
  str_remove_all("[:upper:]{2,}")

# remove Latin characters (mostly editorial notes)
corpus2$text <- corpus2$text %>% 
  str_remove_all("[A-Za-z]")

# remove punctuation
corpus2$text <- corpus2$text %>% 
  str_remove_all("[:punct:]")

# tokenize (this will be a very long data!)
library(tidytext)
corpus2.t <- corpus2 %>% 
  unnest_tokens(word, text)
nrow(corpus2.t) 
```

# Compare text lengths
```{r}
# compare text lengths
corpus2.t %>% group_by(author) %>% 
  count() %>%
  ggplot(aes(x = reorder(author, n), y = n, fill=author)) +
  geom_col(show.legend = F) + 
  coord_flip() + 
  theme_bw() + 
  xlab(NULL)
```

# Select authors with 1 text only
```{r}
Gal_Thuc <- corpus2.t %>% 
  filter(author %in% c("Galen", "Thucydides")) %>%
  group_by(author, work) %>% 
  mutate(sample = round((row_number() + 15000) / 15000)) %>% 
  filter(sample < 4)
```

# Bind texts and samples
```{r}
corpus_all <- corpus2.t %>% 
  filter(!author %in% c("Galen", "Thucydides")) %>% 
  bind_rows(Gal_Thuc)
```

# Shrink Aristotle and Xenophon
```{r}
XA <- corpus_all %>% 
  filter(author %in% c("Aristotle", "Xenophon")) %>% 
  group_by(author, work) %>% 
  mutate(sample = round((row_number() + 15000) / 15000)) %>% 
  filter(sample == 2)

XA %>% count()

corpus_all <- corpus_all %>% 
  filter(!author %in% c("Aristotle", "Xenophon")) %>% 
  bind_rows(XA)
  
```


# Plot
```{r}
# plot
corpus_all %>% group_by(author) %>% 
  count() %>%
  ggplot(aes(x = reorder(author, n), y = n, fill=author)) +
  geom_col(show.legend = F) + 
  coord_flip() + 
  theme_bw() + 
  xlab(NULL)
```

# Corpus Stats
```{r}
corpus_all %>% group_by(author) %>% count()
```


# Ad Group IDs
```{r}
# add group ids
groups <- corpus_all %>% group_by(author, work, sample) %>% 
  mutate(group_id = cur_group_id())
ids <- sort(unique(groups$group_id))
ids
```

# Write files

```{r message=FALSE}
# write files
for(i in ids){
  message(paste("processing sample ", i))
  author <- groups %>% filter(group_id == i) %>% 
    pull(author) %>% unique()
  title <- groups %>% filter(group_id == i) %>% 
    pull(work) %>% unique()
  id <- i
  text <- groups %>% filter(group_id == i) %>% pull(word)
  filename <- paste0(author, "_", title, "_", id, ".txt")
  write.table(text, file = filename, row.names = FALSE, 
              col.names = FALSE, quote = FALSE)
}
```

**For the final_corpus, several txt-files are  deleted manually both from corpus1 (RPerseus) and corpus2 (XML)**

All experiments are made on the final_corpus!!!



